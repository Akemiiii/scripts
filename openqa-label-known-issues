#!/bin/bash -e

set -o pipefail

host="${host:-"openqa.opensuse.org"}"
scheme="${scheme:-"https"}"
host_url="$scheme://$host"
dry_run="${dry_run:-"0"}"
min_search_term="${min_search_term:-"16"}"
issue_marker="${issue_marker:-"auto_review%3A"}"
issue_query="${issue_query:-"https://progress.opensuse.org/projects/openqav3/issues.json?limit=200&subproject_id=*&subject=~${issue_marker}"}"
reason_min_length="${reason_min_length:-"8"}"
to_review=()

echoerr() { echo "$@" >&2; }

label_on_issue() {
    id=$1
    search_term=$2
    comment=$3
    restart=$4
    grep_opts="${grep_opts:-"-qPzo"}"
    check=$5
    # shellcheck disable=SC2086
    if [[ -n $check ]]; then
        eval $check || return 1
    else
        grep $grep_opts "$search_term" "$out" || return 1
    fi
    $client_call jobs/"$id"/comments post text="$comment"
    if [ "$restart" = "1" ]; then
        $client_call jobs/"$id"/restart post
    fi
}

handle_unreachable_or_no_log() {
    local id=$1
    local i=$2
    local out=$3

    if ! curl -s --head "$i" -o /dev/null; then
        # the page might be gone, try the scheme+host we configured (might be different one though)
        if ! grep -q "$host_url" <<< "$i"; then
            echo "'$i' is not reachable and 'host_url' parameter does not match '$i', can not check further, continuing with next"
            return
        fi
        if ! curl -s --head "$host_url"; then
            echo "'$host_url' is not reachable, bailing out"
            curl --head "$host_url"
        fi
        echo "'$i' is not reachable, assuming deleted, continuing with next"
        return
    fi
    # resorting to downloading the job details page instead of the
    # log, overwrites $out
    if ! curl -s "$i" -o "$out"; then
        echo "'$i' can be reached but not downloaded, bailing out"
        curl "$i"
        exit 2
    fi
    # if the page is there but not even an autoinst-log.txt exists
    # then the job might be too old and logs are already deleted.
    # Checking timestamp
    if [[ $(date -uIs -d '-14days') > $(grep timeago "$out" | hxselect -s '\n' -c '.timeago::attr(title)') ]]; then
        echo "'$i' does not have autoinst-log.txt but is rather old, ignoring"
        return
    fi
    if hxnormalize -x "$out" | hxselect -s '\n' -c '.links_a .resborder' | grep -qPzo '(?s)Gru job failed.*connection error.*Inactivity timeout'; then
        $client_call jobs/"$id"/comments post text='poo#62456 test incompletes after failing in GRU download task on "Inactivity timeout" with no logs'
        $client_call jobs/"$id"/restart post
        return
    fi
    # if the job is not too old but there is no log file it is most
    # likely poo#57620 See "openqa-label-all" as an interesting
    # alternative which can label and optionally restart jobs based on
    # group, build, module parameters
    # As long as we have a ticket for "incomplete jobs with no logs"
    # of higher priority we should use that one instead:
    $client_call jobs/"$id"/comments post text='poo#61922 Incomplete jobs with no logs at all'
    #$client_call jobs/"$id"/comments post text='poo#57620 job is incomplete if websockets server (or webui?) is unreachable for a minute, e.g. during upgrade'
    # triggering a restart on jobs that already have a clone does not have an effect
    $client_call jobs/"$id"/restart post
}

label_on_issues_from_issue_tracker() {
    local id=$1
    # query progress.o.o for all subjects with
    # 'issue_marker:"<search_term>"[:retry]' with <search_term> being the
    # perl extended regex to search for and an optional boolean switch
    # ':retry' after the quoted search term to instruct for retriggering
    # the according openQA job. The search terms are crosschecked against
    # the logfiles of the openQA jobs against these issues.
    #
    # Detailed explanation:
    # it is possible to search for issues with a subject search term, e.g.:
    # curl -s "https://progress.opensuse.org/projects/openqav3/issues.json?subject=~merge%20keys" | jq '.issues | .[] | .id'
    # this reads out all progress issues that have the search term included and
    # splice each line with a call to label_on_issue
    echo "$issues" | (while read -r issue; do
        read -r subject
        after=${subject#*\"} && search=${after%\"*} && [[ ${#search} -ge $min_search_term ]] && label_on_issue "$id" "$search" "poo#$issue $subject" "${after//*\":retry*/1}" && break; done)
}

label_on_issues_without_tickets() {
    if label_on_issue "$id" '(?s)([dD]ownload.*failed.*404).*Result: setup failure' 'label:non_existing asset, candidate for removal or wrong settings'; then return
    elif label_on_issue "$id" 'File .*\.yaml.* does not exist at .*scheduler.pm' 'label:missing_schedule_file'; then return
    elif label_on_issue "$id" 'Compilation failed in require at .*isotovideo line 28.' 'label:schedule_compilation_error'; then return
    elif label_on_issue "$id" 'qemu-img: Could not open .*: No such file or directory' 'label:missing_asset'; then return
    elif label_on_issue "$id" 'fatal: Remote branch .* not found' 'label:remote_branch_not_found, probably wrong custom git URL specified with branch'; then return
    elif label_on_issue "$id" 'fatal: repository not found' 'label:remote_repo_not_found, probably wrong custom git URL specified'; then return
    elif label_on_issue "$id" '(?s)Cloning git URL.*to use as test distribution.*(No scripts in|needledir not found)' 'label:remote_repo_invalid, probably wrong custom git URL specified'; then return
    elif label_on_issue "$id" '(?s)Cloning git URL.*to use as test distribution.*(SCHEDULE.*not set|loadtest needs a script below)' 'label:remote_repo_schedule_not_found, probably wrong custom git URL + PRODUCTDIR specified'; then return
    elif label_on_issue "$id" '\[error\] Failed to download' 'label:download_error potentially out-of-space worker?' 1; then return
    fi
    false
}

handle_unknown() {
    local i=$1 out=$2 reason=$3
    to_review+=("$i ${reason:0:50}")
    echoerr "$i : Unknown issue, to be reviewed -> $i/file/autoinst-log.txt"
    echoerr -e "Likely the error is within this log excerpt, last lines before shutdown:\n---"
    # Look for different termination points with likely context
    (grep -A 12 'Backend process died, backend errors are reported below in the following lines' "$out" || grep -B 10 'sending magic and exit' "$out" || grep -B 5 'killing command server.*because test execution ended through exception' "$out" || grep -B 5 'EXIT 1' "$out" || grep -B 10 '\(Result: died\|isotovideo failed\)' "$out" || echo '(No log excerpt found)') | head -n -1 >&2
    echoerr "---"
}

investigate_issue() {
    local id="${1##*/}"
    local out
    local reason
    local curl
    out=$(mktemp)
    curl=$(curl -s -w "%{http_code}" "$i/file/autoinst-log.txt" -o "$out")
    # combine both the reason and autoinst-log.txt to check known issues
    # against even in case when autoinst-log.txt is missing the details, e.g.
    # see https://progress.opensuse.org/issues/69178
    echo "$reason" >> "$out"
    if [[ "$curl" != "200" ]]; then
        # if we can not even access the page it is something more critical
        handle_unreachable_or_no_log "$id" "$i" "$out"
    elif label_on_issues_from_issue_tracker "$id"; then return

    ## Issues without tickets, e.g. potential singular, manual debug jobs,
    # wrong user settings, etc.
    # could create an issue automatically with
    # $client_prefix curl -s -H "Content-Type: application/json" -X POST -H "X-Redmine-API-Key: $(sed -n 's/redmine-token = //p' ~/.query_redminerc)" --data '{"issue": {"project_id": 36, "category_id": 152, priority_id: 5, "subject": "test from command line"}}' https://progress.opensuse.org/issues.json
    # but we should check if the issue already exists, e.g. same
    # subject line
    elif label_on_issues_without_tickets "$id"; then return
    else
        handle_unknown "$i" "$out" "$reason"
    fi
    rm "$out"
}

print_summary() {
    local to_review_count=${#to_review[@]}
    [[ $to_review_count -eq 0 ]] && return
    local msg="\n\e[1m\e[31m$to_review_count unknown issues to be reviewed:\e[0m"
    for job in "${to_review[@]}"; do
        msg+="\n - $job"
    done
    echoerr -e "$msg"
}

main() {
    [ "$dry_run" = "1" ] && client_prefix="echo"
    client_call="${client_call:-"$client_prefix openqa-client --host $host_url"}"
    issues=$(curl -s "$issue_query" | jq -r '.issues | .[] | (.id,.subject)')
    # shellcheck disable=SC2013
    for i in $(cat - | sed 's/ .*$//'); do
        investigate_issue "$i"
    done
    print_summary
}

main
